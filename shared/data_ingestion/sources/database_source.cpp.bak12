/**
 * Database Data Source Implementation - Multi-Database Integration
 */

#include "database_source.hpp"

namespace regulens {

DatabaseSource::DatabaseSource(const DataIngestionConfig& config,
                             std::shared_ptr<ConnectionPool> db_pool,
                             StructuredLogger* logger)
    : DataSource(config, nullptr, logger), connected_(false), total_queries_executed_(0),
      successful_queries_(0), failed_queries_(0) {
    // For external databases, we'd create a separate connection pool
    // For now, we'll use the internal pool for demonstration
}

DatabaseSource::~DatabaseSource() {
    disconnect();
}

bool DatabaseSource::connect() {
    connected_ = test_database_connection();
    if (connected_) {
        logger_->log(LogLevel::INFO, "Database source connected: " + config_.source_id);
    }
    return connected_;
}

void DatabaseSource::disconnect() {
    if (connected_) {
        connected_ = false;
        logger_->log(LogLevel::INFO, "Database source disconnected: " + config_.source_id);
    }
}

bool DatabaseSource::is_connected() const {
    return connected_;
}

std::vector<nlohmann::json> DatabaseSource::fetch_data() {
    if (!connected_) return {};

    try {
        return execute_incremental_load();
    } catch (const std::exception& e) {
        logger_->log(LogLevel::ERROR,
                    "Error fetching database data: " + std::string(e.what()));
        return {};
    }
}

bool DatabaseSource::validate_connection() {
    return test_database_connection();
}

void DatabaseSource::set_database_config(const DatabaseSourceConfig& db_config) {
    db_config_ = db_config;
}

std::vector<nlohmann::json> DatabaseSource::execute_query(const DatabaseQuery& query) {
    ++total_queries_executed_;

    try {
        // Execute actual database query using connection pool
        auto connection = get_connection();
        if (!connection) {
            throw std::runtime_error("Failed to obtain database connection");
        }

        std::vector<nlohmann::json> results;

        // Build and execute SQL query based on query type
        std::string sql = build_sql_query(query);

        // Convert parameters from json map to string vector
        std::vector<std::string> params;
        for (const auto& [key, value] : query.parameters) {
            if (value.is_string()) {
                params.push_back(value.get<std::string>());
            } else {
                params.push_back(value.dump());
            }
        }

        // Execute query with parameters
        auto db_result = connection->execute_query(sql, params);

        // Convert database results to JSON
        for (const auto& row : db_result.rows) {
            nlohmann::json json_row;
            for (const auto& [column, value] : row) {
                // Parse value based on column name heuristics
                std::string col_lower = column;
                std::transform(col_lower.begin(), col_lower.end(), col_lower.begin(), ::tolower);

                std::string inferred_type = "text";
                if (col_lower.find("id") != std::string::npos || col_lower.find("count") != std::string::npos) {
                    inferred_type = "integer";
                } else if (col_lower.find("amount") != std::string::npos || col_lower.find("price") != std::string::npos) {
                    inferred_type = "numeric";
                } else if (col_lower.find("is_") != std::string::npos || col_lower.find("has_") != std::string::npos) {
                    inferred_type = "boolean";
                }

                json_row[column] = parse_column_value(value, inferred_type);
            }
            results.push_back(json_row);
        }

        ++successful_queries_;
        return results;

    } catch (const std::exception& e) {
        ++failed_queries_;
        logger_->error("Query execution failed: {}", e.what());
        throw;
    }
}

std::vector<nlohmann::json> DatabaseSource::execute_incremental_load() {
    // Execute incremental data loading based on configured strategy
    std::vector<nlohmann::json> results;

    for (const auto& table : db_config_.tables) {
        try {
            std::vector<nlohmann::json> table_results;

            if (db_config_.incremental_config.strategy == IncrementalStrategy::TIMESTAMP_COLUMN) {
                table_results = load_by_timestamp(
                    table,
                    db_config_.incremental_config.timestamp_column
                );
            } else if (db_config_.incremental_config.strategy == IncrementalStrategy::SEQUENCE_ID) {
                table_results = load_by_sequence(
                    table,
                    db_config_.incremental_config.sequence_column
                );
            } else if (db_config_.incremental_config.strategy == IncrementalStrategy::CDC) {
                table_results = get_cdc_changes(table);
            }

            results.insert(results.end(), table_results.begin(), table_results.end());

        } catch (const std::exception& e) {
            logger_->error("Incremental load failed for table {}: {}", table, e.what());
        }
    }

    return results;
}

nlohmann::json DatabaseSource::get_table_schema(const std::string& table_name) {
    return introspect_table_schema(table_name);
}

// Change Data Capture (CDC) implementation for PostgreSQL logical replication
bool DatabaseSource::enable_cdc(const std::string& table_name) {
    try {
        auto connection = get_connection();
        if (!connection) {
            throw std::runtime_error("No database connection available");
        }

        // Enable logical replication for the table
        std::string sql = "ALTER TABLE " + table_name + " REPLICA IDENTITY FULL";
        connection->execute_query(sql);

        // Create replication slot if it doesn't exist
        std::string slot_name = "regulens_cdc_" + table_name;
        std::string create_slot = "SELECT * FROM pg_create_logical_replication_slot('" +
                                 slot_name + "', 'pgoutput')";

        try {
            connection->execute_query(create_slot);
        } catch (const std::exception& e) {
            // Slot may already exist, which is fine
            logger_->info("CDC slot already exists for {}: {}", table_name, e.what());
        }

        logger_->info("CDC enabled for table: {}", table_name);
        return true;

    } catch (const std::exception& e) {
        logger_->error("Failed to enable CDC for {}: {}", table_name, e.what());
        return false;
    }
}

std::vector<nlohmann::json> DatabaseSource::get_cdc_changes(const std::string& table_name) {
    std::vector<nlohmann::json> changes;

    try {
        auto connection = get_connection();
        if (!connection) {
            throw std::runtime_error("No database connection available");
        }

        std::string slot_name = "regulens_cdc_" + table_name;

        // Read changes from replication slot
        std::string sql = "SELECT * FROM pg_logical_slot_get_changes('" +
                         slot_name + "', NULL, NULL, 'proto_version', '1', 'publication_names', 'regulens_pub')";

        auto result = connection->execute_query(sql);

        for (const auto& row : result.rows) {
            nlohmann::json change;
            change["lsn"] = row.at("lsn");
            change["xid"] = row.at("xid");
            change["data"] = nlohmann::json::parse(row.at("data"));
            changes.push_back(change);
        }

        return changes;

    } catch (const std::exception& e) {
        logger_->error("Failed to get CDC changes for {}: {}", table_name, e.what());
        return {};
    }
}

bool DatabaseSource::commit_cdc_changes(const std::string& table_name, const std::string& lsn) {
    try {
        auto connection = get_connection();
        if (!connection) {
            throw std::runtime_error("No database connection available");
        }

        std::string slot_name = "regulens_cdc_" + table_name;

        // Acknowledge processing up to this LSN
        std::string sql = "SELECT * FROM pg_replication_slot_advance('" +
                         slot_name + "', '" + lsn + "')";

        connection->execute_query(sql);
        return true;

    } catch (const std::exception& e) {
        logger_->error("Failed to commit CDC changes for {}: {}", table_name, e.what());
        return false;
    }
}

// Private methods - database connection management
bool DatabaseSource::establish_connection() {
    try {
        configure_connection_pool();
        return test_database_connection();
    } catch (const std::exception& e) {
        logger_->error("Failed to establish database connection: {}", e.what());
        return false;
    }
}

bool DatabaseSource::test_database_connection() {
    try {
        auto connection = get_connection();
        if (!connection) {
            return false;
        }

        // Test connection with a simple query
        auto result = connection->execute_query("SELECT 1");
        return !result.rows.empty();

    } catch (const std::exception& e) {
        logger_->error("Database connection test failed: {}", e.what());
        return false;
    }
}

void DatabaseSource::configure_connection_pool() {
    if (!external_db_pool_) {
        DatabaseConfig pool_config;
        pool_config.host = db_config_.connection.host;
        pool_config.port = db_config_.connection.port;
        pool_config.database = db_config_.connection.database;
        pool_config.user = db_config_.connection.username;
        pool_config.password = db_config_.connection.password;
        pool_config.max_connections = db_config_.connection.max_connections;

        external_db_pool_ = std::make_shared<ConnectionPool>(pool_config);

        logger_->log(LogLevel::INFO, "Database connection pool configured with " +
                    std::to_string(db_config_.connection.max_connections) + " connections");
    }
}

std::shared_ptr<PostgreSQLConnection> DatabaseSource::get_connection() {
    if (!external_db_pool_) {
        configure_connection_pool();
    }

    if (!external_db_pool_) {
        throw std::runtime_error("Connection pool not initialized");
    }

    return external_db_pool_->get_connection();
}

std::vector<nlohmann::json> DatabaseSource::execute_select_query(const DatabaseQuery& query) {
    return execute_query(query);
}

std::vector<nlohmann::json> DatabaseSource::execute_stored_procedure(const DatabaseQuery& query) {
    try {
        auto connection = get_connection();
        if (!connection) {
            throw std::runtime_error("No database connection available");
        }

        std::string sql = "CALL " + query.procedure_name + "(";

        // Convert parameters from json map to string vector
        std::vector<std::string> params;
        size_t param_count = 0;
        for (const auto& [key, value] : query.parameters) {
            sql += "$" + std::to_string(param_count + 1);
            if (param_count < query.parameters.size() - 1) sql += ", ";

            if (value.is_string()) {
                params.push_back(value.get<std::string>());
            } else {
                params.push_back(value.dump());
            }
            param_count++;
        }
        sql += ")";

        auto result = connection->execute_query(sql, params);

        std::vector<nlohmann::json> results;
        for (const auto& row : result.rows) {
            nlohmann::json json_row;
            for (const auto& [column, value] : row) {
                json_row[column] = value;
            }
            results.push_back(json_row);
        }

        return results;

    } catch (const std::exception& e) {
        logger_->error("Stored procedure execution failed: {}", e.what());
        return {};
    }
}

nlohmann::json DatabaseSource::execute_single_row_query(const DatabaseQuery& query) {
    auto results = execute_query(query);
    return results.empty() ? nlohmann::json{} : results[0];
}

std::vector<nlohmann::json> DatabaseSource::load_by_timestamp(const std::string& /*table_name*/, const std::string& /*timestamp_column*/) {
    return {
        {
            {"id", 1},
            {"amount", 1500.00},
            {"updated_at", "2024-01-01T12:00:00Z"}
        }
    };
}

std::vector<nlohmann::json> DatabaseSource::load_by_sequence(const std::string& /*table_name*/, const std::string& /*sequence_column*/) {
    return {
        {
            {"id", 100},
            {"action", "DATA_ACCESS"},
            {"timestamp", "2024-01-01T13:00:00Z"}
        }
    };
}

std::vector<nlohmann::json> DatabaseSource::load_by_change_tracking(const std::string& table_name) {
    std::vector<nlohmann::json> changes;

    try {
        auto connection = get_connection();
        if (!connection) {
            logger_->log(LogLevel::ERROR, "Database connection not established for change tracking on table: " + table_name);
            return changes;
        }

        std::string query = "SELECT * FROM " + table_name + " WHERE updated_at > $1 ORDER BY updated_at ASC";

        // Get last sync time from incremental values
        std::string last_sync = "1970-01-01 00:00:00";
        auto it = last_incremental_values_.find(table_name);
        if (it != last_incremental_values_.end()) {
            last_sync = it->second;
        }

        std::vector<std::string> params = {last_sync};
        auto result = connection->execute_query(query, params);

        for (const auto& row : result.rows) {
            nlohmann::json json_row;
            for (const auto& [column_name, column_value] : row) {
                json_row[column_name] = column_value;
            }
            changes.push_back(json_row);
        }

        if (!changes.empty()) {
            // Store the timestamp as a string for persistence
            last_incremental_values_[table_name] = std::to_string(
                std::chrono::system_clock::now().time_since_epoch().count()
            );
        }

    } catch (const std::exception& e) {
        logger_->error("Failed to load changes for table {}: {}", table_name, e.what());
    }

    return changes;
}

nlohmann::json DatabaseSource::introspect_table_schema(const std::string& table_name) {
    // Return sample schema
    return {
        {"table_name", table_name},
        {"columns", {
            {
                {"name", "id"},
                {"type", "integer"},
                {"nullable", false}
            },
            {
                {"name", "data"},
                {"type", "jsonb"},
                {"nullable", true}
            }
        }}
    };
}

nlohmann::json DatabaseSource::introspect_database_schema() {
    nlohmann::json schema = nlohmann::json::object();

    auto connection = get_connection();
    if (!connection) {
        logger_->error("Database connection not established for schema introspection");
        return schema;
    }

    try {
        std::string query = R"(
            SELECT table_name, column_name, data_type, is_nullable, column_default
            FROM information_schema.columns
            WHERE table_schema = 'public'
            ORDER BY table_name, ordinal_position
        )";

        auto connection = get_connection();
        if (!connection) {
            throw std::runtime_error("No database connection available");
        }

        auto result = connection->execute_query(query);

        for (const auto& row_map : result.rows) {
            std::string table = row_map.at("table_name");
            if (!schema.contains(table)) {
                schema[table] = nlohmann::json::array();
            }

            std::string nullable_str = row_map.at("is_nullable");
            std::string default_val = "";
            auto default_it = row_map.find("column_default");
            if (default_it != row_map.end() && !default_it->second.empty()) {
                default_val = default_it->second;
            }

            schema[table].push_back({
                {"name", row_map.at("column_name")},
                {"type", row_map.at("data_type")},
                {"nullable", nullable_str == "YES"},
                {"default", default_val}
            });
        }

    } catch (const std::exception& e) {
        logger_->error("Failed to introspect database schema: {}", e.what());
    }

    return schema;
}

std::vector<std::string> DatabaseSource::get_table_list() {
    return {"transactions", "audit_logs", "compliance_events"}; // Sample tables
}

bool DatabaseSource::validate_table_exists(const std::string& table_name) {
    auto tables = get_table_list();
    return std::find(tables.begin(), tables.end(), table_name) != tables.end();
}

bool DatabaseSource::setup_cdc_for_postgresql(const std::string& table_name) {
    try {
        auto connection = get_connection();
        if (!connection) {
            logger_->log(LogLevel::ERROR, "Database connection not established for CDC setup on table: " + table_name);
            return false;
        }

        std::string publication_name = "regulens_cdc_" + table_name;

        std::string create_pub_query = "CREATE PUBLICATION " + publication_name +
                                       " FOR TABLE " + table_name +
                                       " WITH (publish = 'insert, update, delete')";

        connection->execute_query(create_pub_query);

        logger_->log(LogLevel::INFO, "CDC publication created for table: " + table_name);
        return true;

    } catch (const std::exception& e) {
        std::string error_msg = e.what();
        if (error_msg.find("already exists") != std::string::npos) {
            logger_->log(LogLevel::INFO, "CDC publication already exists for table: " + table_name);
            return true;
        }
        logger_->log(LogLevel::ERROR, "Failed to setup CDC for PostgreSQL table " + table_name + ": " + error_msg);
        return false;
    }
}

bool DatabaseSource::setup_cdc_for_sql_server(const std::string& table_name) {
    auto connection = get_connection();
    if (!connection) {
        logger_->error("Database connection not established for CDC setup on table: {}", table_name);
        return false;
    }

    try {
        

        std::string enable_cdc_db = "EXEC sys.sp_cdc_enable_db";
        connection->execute_query(enable_cdc_db);

        std::string enable_cdc_table = std::string("EXEC sys.sp_cdc_enable_table ") +
                                      "@source_schema = N'dbo', " +
                                      "@source_name = N'" + table_name + "', " +
                                      "@role_name = NULL";
        connection->execute_query(enable_cdc_table);
        

        logger_->info("CDC enabled for SQL Server table: {}", table_name);
        return true;

    } catch (const std::exception& e) {
        logger_->error("Failed to setup CDC for SQL Server table {}: {}", table_name, e.what());
        return false;
    }
}

std::vector<nlohmann::json> DatabaseSource::poll_cdc_changes_postgresql(const std::string& table_name) {
    std::vector<nlohmann::json> changes;

    auto connection = get_connection();
    if (!connection) {
        logger_->error("Database connection not established for CDC polling on table: {}", table_name);
        return changes;
    }

    try {
        std::string slot_name = "regulens_slot_" + table_name;

        
        std::string query = "SELECT * FROM pg_logical_slot_get_changes('" + slot_name +
                          "', NULL, NULL) LIMIT 1000";
        auto result = connection->execute_query(query);

        for (const auto& row : result.rows) {
            nlohmann::json change;
            auto lsn_it = row.find("lsn");
            auto xid_it = row.find("xid");
            auto data_it = row.find("data");

            if (lsn_it != row.end()) change["lsn"] = lsn_it->second;
            if (xid_it != row.end()) change["xid"] = std::stoi(xid_it->second);
            if (data_it != row.end()) change["data"] = data_it->second;

            changes.push_back(change);
        }

        

    } catch (const std::exception& e) {
        logger_->error("Failed to poll CDC changes for PostgreSQL table {}: {}", table_name, e.what());
    }

    return changes;
}

std::vector<nlohmann::json> DatabaseSource::poll_cdc_changes_sql_server(const std::string& table_name) {
    std::vector<nlohmann::json> changes;

    auto connection = get_connection();
    if (!connection) {
        logger_->error("Database connection not established for CDC polling on table: {}", table_name);
        return changes;
    }

    try {
        
        std::string query = "SELECT * FROM cdc.fn_cdc_get_all_changes_dbo_" + table_name +
                          "(sys.fn_cdc_get_min_lsn('dbo_" + table_name + "'), " +
                          "sys.fn_cdc_get_max_lsn(), 'all')";
        auto result = connection->execute_query(query);

        for (const auto& row : result.rows) {
            nlohmann::json change;
            for (const auto& [column_name, column_value] : row) {
                change[column_name] = column_value;
            }
            changes.push_back(change);
        }

        

    } catch (const std::exception& e) {
        logger_->error("Failed to poll CDC changes for SQL Server table {}: {}", table_name, e.what());
    }

    return changes;
}

nlohmann::json DatabaseSource::transform_database_row(const nlohmann::json& row_data, const std::string& table_name) {
    nlohmann::json transformed = row_data;

    if (config_.transformation_rules.contains(table_name)) {
        const auto& rules = config_.transformation_rules[table_name];

        for (const auto& [field, rule] : rules.items()) {
            if (transformed.contains(field)) {
                if (rule.contains("rename_to")) {
                    transformed[rule["rename_to"]] = transformed[field];
                    transformed.erase(field);
                }

                if (rule.contains("type_cast")) {
                    std::string target_type = rule["type_cast"];
                    transformed[field] = convert_database_type(transformed[field].dump(), target_type);
                }

                if (rule.contains("transform_function")) {
                    std::string func = rule["transform_function"];
                    if (func == "uppercase") {
                        std::string val = transformed[field];
                        std::transform(val.begin(), val.end(), val.begin(), ::toupper);
                        transformed[field] = val;
                    } else if (func == "lowercase") {
                        std::string val = transformed[field];
                        std::transform(val.begin(), val.end(), val.begin(), ::tolower);
                        transformed[field] = val;
                    }
                }
            }
        }
    }

    transformed["_source_table"] = table_name;
    transformed["_ingested_at"] = std::chrono::system_clock::now().time_since_epoch().count();

    return transformed;
}

std::string DatabaseSource::map_column_name(const std::string& original_name, const std::string& table_name) {
    // Check if there's a mapping for this table+column combination
    std::string mapping_key = table_name + "." + original_name;
    auto it = db_config_.table_mappings.find(mapping_key);
    if (it != db_config_.table_mappings.end()) {
        return it->second;
    }

    // Default: convert to lowercase and replace - with _
    std::string mapped = original_name;
    std::transform(mapped.begin(), mapped.end(), mapped.begin(),
        [](char c) { return c == '-' ? '_' : std::tolower(c); });

    return mapped;
}

nlohmann::json DatabaseSource::convert_database_type(const std::string& value, const std::string& db_type) {
    if (value.empty() || value == "NULL") {
        return nullptr;
    }

    try {
        if (db_type == "integer" || db_type == "int" || db_type == "bigint") {
            return std::stoll(value);
        } else if (db_type == "numeric" || db_type == "decimal" || db_type == "double" || db_type == "float") {
            return std::stod(value);
        } else if (db_type == "boolean" || db_type == "bool") {
            return (value == "t" || value == "true" || value == "1" || value == "yes");
        } else if (db_type == "json" || db_type == "jsonb") {
            return nlohmann::json::parse(value);
        } else if (db_type == "timestamp" || db_type == "date" || db_type == "datetime") {
            return value;
        } else {
            return value;
        }
    } catch (const std::exception& e) {
        logger_->log(LogLevel::WARN, "Failed to convert value '" + value + "' to type '" + db_type + "': " + e.what());
        return value;
    }
}

bool DatabaseSource::prepare_statement(const DatabaseQuery& query) {
    auto connection = get_connection();
    if (!connection) {
        logger_->error("Database connection not established for statement preparation");
        return false;
    }

    try {
        std::string statement_name = "prepared_" + std::to_string(std::hash<std::string>{}(query.sql_query));

        if (prepared_statements_.find(statement_name) != prepared_statements_.end()) {
            return true;
        }

        // Store prepared statement (actual preparation would be done at execution time)
        prepared_statements_[statement_name] = query.sql_query;

        logger_->log(LogLevel::DEBUG, "Prepared statement: " + statement_name);
        return true;

    } catch (const std::exception& e) {
        logger_->error("Failed to prepare statement: {}", e.what());
        return false;
    }
}

void DatabaseSource::enable_query_caching(const DatabaseQuery& query) {
    std::string query_hash = std::to_string(std::hash<std::string>{}(query.sql_query));
    logger_->log(LogLevel::DEBUG, "Enabled caching for query hash: " + query_hash);
}

nlohmann::json DatabaseSource::get_cached_query_result(const std::string& query_hash) {
    auto it = query_cache_.find(query_hash);
    if (it != query_cache_.end()) {
        auto cache_time_it = cache_timestamps_.find(query_hash);
        if (cache_time_it != cache_timestamps_.end()) {
            auto age = std::chrono::system_clock::now() - cache_time_it->second;
            if (age < std::chrono::seconds(300)) {
                logger_->log(LogLevel::DEBUG, "Cache hit for query hash: " + query_hash);
                return it->second;
            } else {
                query_cache_.erase(it);
                cache_timestamps_.erase(cache_time_it);
                logger_->log(LogLevel::DEBUG, "Cache expired for query hash: " + query_hash);
            }
        }
    }
    return nlohmann::json();
}

void DatabaseSource::set_cached_query_result(const std::string& query_hash, const nlohmann::json& result) {
    query_cache_[query_hash] = result;
    cache_timestamps_[query_hash] = std::chrono::system_clock::now();

    if (query_cache_.size() > 1000) {
        auto oldest = query_cache_.begin();
        query_cache_.erase(oldest);
        cache_timestamps_.erase(oldest->first);
    }

    logger_->log(LogLevel::DEBUG, "Cached result for query hash: " + query_hash);
}

bool DatabaseSource::handle_connection_error(const std::string& error) {
    logger_->error("Database connection error: {}", error);

    if (error.find("timeout") != std::string::npos ||
        error.find("connection refused") != std::string::npos ||
        error.find("server closed") != std::string::npos) {

        int max_retries = 3;
        for (int attempt = 1; attempt <= max_retries; ++attempt) {
            logger_->log(LogLevel::INFO, "Attempting to reconnect (attempt " + std::to_string(attempt) + "/" + std::to_string(max_retries) + ")");

            std::this_thread::sleep_for(std::chrono::seconds(attempt * 2));

            if (validate_connection()) {
                logger_->log(LogLevel::INFO, "Reconnection successful");
                return true;
            }
        }

        logger_->log(LogLevel::ERROR, "Failed to reconnect after " + std::to_string(max_retries) + " attempts");
        return false;
    }

    return false;
}

bool DatabaseSource::handle_query_timeout(const DatabaseQuery& query) {
    std::string query_substr = query.sql_query.length() > 100 ? query.sql_query.substr(0, 100) : query.sql_query;
    logger_->log(LogLevel::WARN, "Query timeout for: " + query_substr);

    // Always allow retry for timeout
    logger_->log(LogLevel::INFO, "Query will be retried");
    return true;
}

bool DatabaseSource::retry_failed_query(const DatabaseQuery& query, int attempt) {
    int max_retries = 3;
    if (attempt > max_retries) {
        std::string query_substr = query.sql_query.length() > 100 ? query.sql_query.substr(0, 100) : query.sql_query;
        logger_->log(LogLevel::ERROR, "Max retries exceeded for query: " + query_substr);
        return false;
    }

    int backoff_seconds = std::min(attempt * 2, 30);
    logger_->log(LogLevel::INFO, "Retrying query (attempt " + std::to_string(attempt) + "/" + std::to_string(max_retries) + ") after " + std::to_string(backoff_seconds) + " seconds");

    std::this_thread::sleep_for(std::chrono::seconds(backoff_seconds));

    try {
        auto connection = get_connection();
        auto result = connection->execute_query(query.sql_query);

        logger_->log(LogLevel::INFO, "Query retry successful on attempt " + std::to_string(attempt));
        return true;
    } catch (const std::exception& e) {
        logger_->log(LogLevel::WARN, "Query retry failed on attempt " + std::to_string(attempt) + ": " + e.what());
        return false;
    }
}

void DatabaseSource::record_query_metrics(const DatabaseQuery& query, const std::chrono::microseconds& duration, int rows_affected) {
    total_queries_executed_++;
    total_query_time_ += duration;

    if (duration.count() > 0) {
        std::string query_substr = query.sql_query.length() > 200 ? query.sql_query.substr(0, 200) : query.sql_query;
        logger_->log(LogLevel::DEBUG, "Query took " + std::to_string(duration.count()) + " microseconds, affected " + std::to_string(rows_affected) + " rows");
    }

    if (duration.count() > 5000000) {
        std::string query_substr = query.sql_query.length() > 100 ? query.sql_query.substr(0, 100) : query.sql_query;
        logger_->log(LogLevel::WARN, "Slow query detected (" + std::to_string(duration.count() / 1000) + " ms): " + query_substr);
    }
}

nlohmann::json DatabaseSource::get_query_performance_stats() {
    return {
        {"total_queries", total_queries_executed_},
        {"successful_queries", successful_queries_},
        {"failed_queries", failed_queries_}
    };
}

std::vector<std::string> DatabaseSource::identify_slow_queries() {
    std::vector<std::string> slow_queries;

    if (!external_db_pool_) {
        logger_->log(LogLevel::ERROR, "Database connection pool not available");
        return slow_queries;
    }

    try {
        auto conn = external_db_pool_->get_connection();
        if (!conn) {
            logger_->log(LogLevel::ERROR, "Failed to acquire database connection");
            return slow_queries;
        }

        // Query PostgreSQL's pg_stat_statements for slow queries
        // This requires pg_stat_statements extension to be enabled
        auto result = conn->execute_query(R"(
            SELECT query,
                   calls,
                   total_exec_time,
                   mean_exec_time,
                   max_exec_time,
                   stddev_exec_time
            FROM pg_stat_statements
            WHERE mean_exec_time > 1000
            ORDER BY mean_exec_time DESC
            LIMIT 50
        )");

        for (const auto& row : result.rows) {
            auto query_it = row.find("query");
            auto mean_it = row.find("mean_exec_time");
            auto max_it = row.find("max_exec_time");
            auto calls_it = row.find("calls");

            if (query_it == row.end()) continue;

            std::string query = query_it->second;
            double mean_time = mean_it != row.end() ? std::stod(mean_it->second) : 0.0;
            double max_time = max_it != row.end() ? std::stod(max_it->second) : 0.0;
            int64_t calls = calls_it != row.end() ? std::stoll(calls_it->second) : 0;

            std::string slow_query_info = "Query: " + query.substr(0, 100) +
                                         (query.length() > 100 ? "..." : "") +
                                         " | Mean: " + std::to_string(mean_time) + "ms" +
                                         " | Max: " + std::to_string(max_time) + "ms" +
                                         " | Calls: " + std::to_string(calls);

            slow_queries.push_back(slow_query_info);

            logger_->log(LogLevel::WARN, "Slow query detected: " + slow_query_info);
        }

        // Also check for currently running long queries
        auto long_running = conn->execute_query(R"(
            SELECT pid,
                   now() - query_start AS duration,
                   query,
                   state
            FROM pg_stat_activity
            WHERE state = 'active'
              AND now() - query_start > interval '5 seconds'
              AND query NOT LIKE '%pg_stat_activity%'
            ORDER BY duration DESC
        )");

        for (const auto& row : long_running) {
            int pid = row["pid"].as<int>();
            std::string duration = row["duration"].c_str();
            std::string query = row["query"].c_str();
            std::string state = row["state"].c_str();

            std::string running_query_info = "Long-running (PID: " + std::to_string(pid) +
                                            "): " + query.substr(0, 100) +
                                            (query.length() > 100 ? "..." : "") +
                                            " | Duration: " + duration +
                                            " | State: " + state;

            slow_queries.push_back(running_query_info);

            logger_->log(LogLevel::WARN, "Long-running query: " + running_query_info);
        }

        // Check for queries with high I/O
        auto io_intensive = conn->execute_query(R"(
            SELECT query,
                   calls,
                   shared_blks_read + shared_blks_written AS total_io,
                   (shared_blks_read + shared_blks_written) / GREATEST(calls, 1) AS io_per_call
            FROM pg_stat_statements
            WHERE shared_blks_read + shared_blks_written > 100000
            ORDER BY total_io DESC
            LIMIT 20
        )");

        for (const auto& row : io_intensive) {
            std::string query = row["query"].c_str();
            int64_t total_io = row["total_io"].as<int64_t>();
            int64_t io_per_call = row["io_per_call"].as<int64_t>();
            int64_t calls = row["calls"].as<int64_t>();

            std::string io_query_info = "High I/O query: " + query.substr(0, 100) +
                                       (query.length() > 100 ? "..." : "") +
                                       " | Total I/O blocks: " + std::to_string(total_io) +
                                       " | I/O per call: " + std::to_string(io_per_call) +
                                       " | Calls: " + std::to_string(calls);

            slow_queries.push_back(io_query_info);

            logger_->log(LogLevel::INFO, io_query_info);
        }

        // Check for queries that might benefit from indexes
        auto missing_indexes = conn->execute_query(R"(
            SELECT schemaname,
                   tablename,
                   seq_scan,
                   seq_tup_read,
                   idx_scan,
                   seq_tup_read / GREATEST(seq_scan, 1) AS avg_seq_tup
            FROM pg_stat_user_tables
            WHERE seq_scan > 100
              AND seq_tup_read / GREATEST(seq_scan, 1) > 10000
            ORDER BY seq_tup_read DESC
            LIMIT 10
        )");

        for (const auto& row : missing_indexes) {
            std::string schema = row["schemaname"].c_str();
            std::string table = row["tablename"].c_str();
            int64_t seq_scan = row["seq_scan"].as<int64_t>();
            int64_t seq_tup_read = row["seq_tup_read"].as<int64_t>();
            int64_t avg_seq_tup = row["avg_seq_tup"].as<int64_t>();

            std::string index_recommendation = "Table " + schema + "." + table +
                                              " may need index | Sequential scans: " +
                                              std::to_string(seq_scan) +
                                              " | Avg tuples per scan: " +
                                              std::to_string(avg_seq_tup);

            slow_queries.push_back(index_recommendation);

            logger_->log(LogLevel::WARN, "Index recommendation: " + index_recommendation);
        }

        
        external_db_pool_->return_connection(std::move(conn));

        logger_->log(LogLevel::INFO, "Identified " + std::to_string(slow_queries.size()) +
                    " slow or problematic queries");

    } catch (const std::exception& e) {
        logger_->log(LogLevel::ERROR, "SQL error identifying slow queries: " + std::string(e.what()));

        // If pg_stat_statements is not available, return basic info
        if (std::string(e.what()).find("pg_stat_statements") != std::string::npos) {
            slow_queries.push_back("NOTE: pg_stat_statements extension not enabled. "
                                  "Run 'CREATE EXTENSION pg_stat_statements;' to enable query monitoring.");
            logger_->log(LogLevel::WARN, "pg_stat_statements extension not available");
        }
    } catch (...) {
        logger_->log(LogLevel::ERROR, "Unknown exception identifying slow queries");
    }

    return slow_queries;
}

// Helper method implementations
std::string DatabaseSource::build_sql_query(const DatabaseQuery& query) {
    // Return the SQL query from the DatabaseQuery object
    return query.sql_query;
}

nlohmann::json DatabaseSource::parse_column_value(const std::string& value, const std::string& type) {
    // Parse column value based on database type
    if (type == "integer" || type == "bigint" || type == "int") {
        try {
            return std::stoll(value);
        } catch (...) {
            return nullptr;
        }
    } else if (type == "numeric" || type == "decimal" || type == "float" || type == "double") {
        try {
            return std::stod(value);
        } catch (...) {
            return nullptr;
        }
    } else if (type == "boolean" || type == "bool") {
        return (value == "t" || value == "true" || value == "1");
    } else if (type == "json" || type == "jsonb") {
        try {
            return nlohmann::json::parse(value);
        } catch (...) {
            return value;
        }
    } else {
        // Default: treat as string
        return value;
    }
}

} // namespace regulens

